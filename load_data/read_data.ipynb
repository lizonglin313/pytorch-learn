{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 与 DataLoader 读取数据\n",
    "\n",
    "Dataset类表示数据集，通过继承Dataset自定义数据集格式、大小和属性，以供后面的DataLoader使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset类\n",
    "继承此类需要重写:\n",
    "- \\_\\_init\\_\\_() 构造函数 可以自定义数据读取方法和数据预处理\n",
    "- \\_\\_len\\_\\_()  返回数据集大小\n",
    "- \\_\\_getitem\\_\\_() 索引数据集中某一个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Tensor类型的数据集\n",
    "class MyDateset(Dataset):\n",
    "    # 构造函数\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "    # 返回数据集大小\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "    # 返回索引的数据与标签\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7899,  0.2831,  0.4905],\n",
       "         [ 0.4736,  0.6144,  0.4065],\n",
       "         [-0.8576,  0.0502, -1.1867],\n",
       "         [-0.7946,  0.4233,  0.4343],\n",
       "         [ 1.5250, -0.7599,  1.0228],\n",
       "         [ 0.7295,  0.3408,  0.8373],\n",
       "         [-0.1250,  0.3268, -2.1309],\n",
       "         [-1.6104, -0.8479, -1.9267],\n",
       "         [ 0.3549, -0.0297,  0.6682],\n",
       "         [-0.7354, -1.3689,  1.9006]]),\n",
       " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成数据\n",
    "data_tensor = torch.randn(10, 3)    # randn 均值为0 方差为1 的标准正态分布\n",
    "target_tensor = torch.randint(2, (10,))\n",
    "data_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 10\n",
      "tensor_data[0]: (tensor([-0.7899,  0.2831,  0.4905]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "# 将数据封装为Dataset\n",
    "my_dataset = MyDateset(data_tensor=data_tensor, target_tensor=target_tensor)\n",
    "print('Dataset size:', len(my_dataset))\n",
    "print('tensor_data[0]:', my_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader 类\n",
    "如果数据量很大，考虑内存、IO问题，训练过程中不会将数据一次性全部加载到内存中，也可能用多个进程去加载，所以需要多进程，迭代加载。\n",
    "DataLoader就是根据以上需求设计的。\n",
    "\n",
    "DataLoader 是一个迭代器，最基本的使用方法就是传入一个 Dataset 对象，它会根据参数 batch_size 的值生成一个 batch 的数据，节省内存的同时，它还可以实现多进程、数据打乱等处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8576,  0.0502, -1.1867],\n",
      "        [ 0.4736,  0.6144,  0.4065]]) tensor([0, 0])\n",
      "tensor([[-0.7946,  0.4233,  0.4343],\n",
      "        [-0.7899,  0.2831,  0.4905]]) tensor([0, 0])\n",
      "tensor([[ 1.5250, -0.7599,  1.0228],\n",
      "        [ 0.3549, -0.0297,  0.6682]]) tensor([1, 1])\n",
      "tensor([[-0.1250,  0.3268, -2.1309],\n",
      "        [ 0.7295,  0.3408,  0.8373]]) tensor([0, 0])\n",
      "tensor([[-0.7354, -1.3689,  1.9006],\n",
      "        [-1.6104, -0.8479, -1.9267]]) tensor([0, 0])\n",
      "One batch tensor data:  [tensor([[-0.7354, -1.3689,  1.9006],\n",
      "        [-1.6104, -0.8479, -1.9267]]), tensor([0, 0])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tensor_dataloader = DataLoader(\n",
    "    dataset=my_dataset,     # 传入的数据集\n",
    "    batch_size=2,           # 输出的 batch 的大小\n",
    "    shuffle=True,           # 是否打乱\n",
    "    num_workers=0           # 进程数 0 表示只有主进程\n",
    "    )\n",
    "\n",
    "for data, target in tensor_dataloader:\n",
    "    print(data, target)\n",
    "\n",
    "# 输出一个 batch\n",
    "print('One batch tensor data: ', iter(tensor_dataloader).next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "# 定义一个transform\n",
    "my_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5), (0.5))\n",
    "                                  ])\n",
    "mnist_dataset = torchvision.datasets.MNIST(\n",
    "    root='D:\\Coding\\Dataset\\MNIST',\n",
    "    train=True,\n",
    "    transform=my_transform,\n",
    "    target_transform=None, \n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_list = list(mnist_dataset)\n",
    "print(mnist_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label is: 5\n"
     ]
    }
   ],
   "source": [
    "display(mnist_dataset_list[0][0])\n",
    "print(\"Image label is:\", mnist_dataset_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看变换后的数据类型\n",
    "item = mnist_dataset.__getitem__(0)\n",
    "print(type(item[0]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcf34018491d9bd3ef31166662b4dd1e52e7c1b62f1d6d6644835049dcdb0d97"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
